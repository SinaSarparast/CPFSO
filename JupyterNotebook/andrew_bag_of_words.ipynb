{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "      <th>cuisines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plain flour ground pepper salt tomatoes ground...</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eggs pepper salt mayonaise cooking oil green c...</td>\n",
       "      <td>filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>black pepper shallots cornflour cayenne pepper...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ingredients     cuisines\n",
       "0  romaine lettuce black olives grape tomatoes ga...        greek\n",
       "1  plain flour ground pepper salt tomatoes ground...  southern_us\n",
       "2  eggs pepper salt mayonaise cooking oil green c...     filipino\n",
       "3                     water vegetable oil wheat salt       indian\n",
       "4  black pepper shallots cornflour cayenne pepper...       indian"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare training ingredients-cuisines dataframe\n",
    "\n",
    "train_dataframe_file_path = os.path.join(data_directory, \"train.pkl\")\n",
    "\n",
    "if(not pathlib.Path(train_dataframe_file_path).is_file()):\n",
    "    \n",
    "    # Warning!!! Avoid runing this if existing dataframe exists, check\n",
    "    # for .pkl file in Dataset folder\n",
    "    \n",
    "    columnLabels = np.array(['ingredients', 'cuisines'])\n",
    "\n",
    "    trainDf = pd.DataFrame(columns=columnLabels)\n",
    "\n",
    "    print(\"index type: \" + str(trainDf.index.dtype))\n",
    "\n",
    "    # Populate and save ingredients-cuisines dataframe\n",
    "\n",
    "    index = 0;\n",
    "    for dish in trainData:\n",
    "        ingredientStr = \" \".join(dish['ingredients'])\n",
    "        trainDf.loc[index] = [ingredientStr, dish['cuisine']]\n",
    "        index+=1\n",
    "        \n",
    "    trainDf.to_pickle(train_dataframe_file_path)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    trainDf = pd.read_pickle(train_dataframe_file_path)\n",
    "\n",
    "trainDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baking powder eggs all-purpose flour raisins m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sugar egg yolks corn starch cream of tartar ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sausage links fennel bulb fronds olive oil cub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meat cuts file powder smoked sausage okra shri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ground black pepper salt sausage casings leeks...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ingredients\n",
       "0  baking powder eggs all-purpose flour raisins m...\n",
       "1  sugar egg yolks corn starch cream of tartar ba...\n",
       "2  sausage links fennel bulb fronds olive oil cub...\n",
       "3  meat cuts file powder smoked sausage okra shri...\n",
       "4  ground black pepper salt sausage casings leeks..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare testing ingredients-cuisines dataframe\n",
    "\n",
    "test_dataframe_file_path = os.path.join(data_directory, \"test.pkl\")\n",
    "\n",
    "if(not pathlib.Path(test_dataframe_file_path).is_file()):\n",
    "    \n",
    "    # Warning!!! Avoid runing this if existing dataframe exists, check\n",
    "    # for .pkl file in Dataset folder\n",
    "    \n",
    "    columnLabels = np.array(['ingredients'])\n",
    "\n",
    "    testDf = pd.DataFrame(columns=columnLabels)\n",
    "\n",
    "    print(\"index type: \" + str(testDf.index.dtype))\n",
    "\n",
    "    # Populate and save ingredients-cuisines dataframe\n",
    "\n",
    "    index = 0;\n",
    "    for dish in testData:\n",
    "        testDf.loc[index] = \" \".join(dish['ingredients'])\n",
    "        index+=1\n",
    "        \n",
    "    testDf.to_pickle(test_dataframe_file_path)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    testDf = pd.read_pickle(test_dataframe_file_path)\n",
    "\n",
    "testDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'no. unique ingredients: 6714'\n",
      "'no. unique cuisines: 20'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Feel free to skip this part)\n",
    "# Extract unique ingredients and cuisines words\n",
    "\n",
    "ingredients = set()\n",
    "cuisines = set()\n",
    "\n",
    "for dish in trainData:\n",
    "    cuisines.add(dish['cuisine'])\n",
    "    for ingred in dish['ingredients']:\n",
    "        ingredients.add(ingred)\n",
    "\n",
    "prettyPrinter.pprint('no. unique ingredients: '+ str(len(ingredients)))\n",
    "prettyPrinter.pprint('no. unique cuisines: '+ str(len(cuisines)))\n",
    "\n",
    "unique_ingredients_data_file_path = os.path.join(data_directory, \"unique_ingredients.txt\")\n",
    "unique_cuisines_data_file_path = os.path.join(data_directory, \"unique_cuisines.txt\")\n",
    "\n",
    "# Writing unique ingredients txt file\n",
    "with open(unique_ingredients_data_file_path, 'w') as file:\n",
    "     file.write('\\n'.join(ingredients))\n",
    "file.closed\n",
    "\n",
    "# Writing unique cuisines txt file\n",
    "with open(unique_cuisines_data_file_path, 'w') as file:\n",
    "     file.write('\\n'.join(cuisines))\n",
    "file.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 3010)\n",
      "(39774, 3010)\n"
     ]
    }
   ],
   "source": [
    "train = {\"data\": trainDf.ingredients, \n",
    "         \"target\": trainDf.cuisines}\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(train['data'])\n",
    "print(train_counts.shape)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "train_tfidf = tfidf_transformer.fit_transform(train_counts)\n",
    "print(train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', OneVsRestClassifier(MultinomialNB()))])\n",
    "text_clf = text_clf.fit(train['data'], train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'toxic_test_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-eecca41daff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m test = {\"data\": toxic_test_raw.comment_text, \n\u001b[0m\u001b[1;32m      3\u001b[0m          \"target\": toxic_test_raw[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values}\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'toxic_test_raw' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test = {\"data\": toxic_test_raw.comment_text, \n",
    "         \"target\": train['target']}\n",
    "\n",
    "predicted = text_clf.predict(test['data'])\n",
    "np.mean(predicted[0:20] == test['target'][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/Documents/COMP6208/AML_CW/env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91538562771430898"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', \n",
    "                                                   penalty='l2',\n",
    "                                                   alpha=1e-3,\n",
    "                                                   n_iter=5,\n",
    "                                                   random_state=42)),\n",
    "                         ])\n",
    "_ = text_clf_svm.fit(train['data'], train['target'])\n",
    "predicted_svm = text_clf_svm.predict(test['data'])\n",
    "np.mean(predicted_svm == test['target'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
